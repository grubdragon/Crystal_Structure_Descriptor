{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from tensorflow_docs.plots import HistoryPlotter\n",
    "#from tensorflow_docs.modeling import EpochDots\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['material_id', 'energy', 'energy_per_atom', 'band_gap',\n",
       "       'total_magnetization', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       '10', '11', '12', '13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "path = \"../data/descriptor/DescriptorData.csv\"\n",
    "df=pd.read_csv(path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_id</th>\n",
       "      <th>energy</th>\n",
       "      <th>energy_per_atom</th>\n",
       "      <th>band_gap</th>\n",
       "      <th>total_magnetization</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16657</th>\n",
       "      <td>mp-19395</td>\n",
       "      <td>-85.492408</td>\n",
       "      <td>-7.124367</td>\n",
       "      <td>1.0729</td>\n",
       "      <td>1.500000e-07</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>2.688062</td>\n",
       "      <td>-0.187277</td>\n",
       "      <td>1.902257</td>\n",
       "      <td>0.004483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      material_id     energy  energy_per_atom  band_gap  total_magnetization  \\\n",
       "16657    mp-19395 -85.492408        -7.124367    1.0729         1.500000e-07   \n",
       "\n",
       "          0    1    2    3    4    5    6    7    8    9        10        11  \\\n",
       "16657  14.5  3.5 -8.5 -5.5  6.0  2.0  4.5  0.5  4.5 -1.5  2.688062 -0.187277   \n",
       "\n",
       "             12        13  \n",
       "16657  1.902257  0.004483  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect data\n",
    "df[df[\"material_id\"]==\"mp-19395\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.20000</td>\n",
       "      <td>-4.800000</td>\n",
       "      <td>4.413094</td>\n",
       "      <td>-1.060947</td>\n",
       "      <td>3.352150</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.805744</td>\n",
       "      <td>-4.097701</td>\n",
       "      <td>6.857758</td>\n",
       "      <td>4.503737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.188573</td>\n",
       "      <td>0.141018</td>\n",
       "      <td>2.782234</td>\n",
       "      <td>0.020056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.074499</td>\n",
       "      <td>0.527501</td>\n",
       "      <td>2.546999</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>3.246873</td>\n",
       "      <td>-0.584746</td>\n",
       "      <td>2.691912</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18957</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.380378</td>\n",
       "      <td>0.891985</td>\n",
       "      <td>2.384921</td>\n",
       "      <td>-0.510342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18958</th>\n",
       "      <td>14.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.153850</td>\n",
       "      <td>-0.563046</td>\n",
       "      <td>2.996383</td>\n",
       "      <td>-0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18959</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.117691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18960</th>\n",
       "      <td>18.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>5.40000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.324509</td>\n",
       "      <td>-1.130982</td>\n",
       "      <td>2.717591</td>\n",
       "      <td>1.195841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18961</th>\n",
       "      <td>12.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>4.691877</td>\n",
       "      <td>2.406162</td>\n",
       "      <td>8.87605</td>\n",
       "      <td>-5.052521</td>\n",
       "      <td>3.480985</td>\n",
       "      <td>-0.678666</td>\n",
       "      <td>3.185616</td>\n",
       "      <td>0.030684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18962 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1     2    3     4     5         6         7        8  \\\n",
       "0       6.5  1.5   1.5  0.5   3.0   2.0  8.800000  0.800000  7.20000   \n",
       "1      17.5  3.5  -9.5 -3.5   1.5   0.5  3.500000 -2.500000  3.00000   \n",
       "2      15.5  5.5  -5.5 -5.5   5.0   1.0  4.333333  2.333333  5.00000   \n",
       "3      13.0  1.0  -5.0 -1.0   2.0  -1.0  7.000000 -1.000000  8.00000   \n",
       "4      12.0  3.0  -3.0 -2.0   4.0   2.0  7.000000  1.000000  8.00000   \n",
       "...     ...  ...   ...  ...   ...   ...       ...       ...      ...   \n",
       "18957  20.0  1.0 -13.0  2.0  10.0  -6.0  2.375000 -0.375000  2.50000   \n",
       "18958  14.5  5.5  -4.5 -7.5   9.0   3.0  4.000000 -0.000000  3.00000   \n",
       "18959  15.0  5.0  -4.0 -8.0   1.0   0.0  6.000000  0.000000  8.00000   \n",
       "18960  18.5  0.5 -13.5 -1.5   6.0   4.0  4.200000 -1.800000  5.40000   \n",
       "18961  12.5  3.5  -1.5 -4.5  32.5  18.5  4.691877  2.406162  8.87605   \n",
       "\n",
       "              9        10        11        12        13  \n",
       "0     -4.800000  4.413094 -1.060947  3.352150  0.000002  \n",
       "1      1.000000  8.805744 -4.097701  6.857758  4.503737  \n",
       "2     -1.000000  3.188573  0.141018  2.782234  0.020056  \n",
       "3      4.000000  3.074499  0.527501  2.546999 -0.000000  \n",
       "4     -4.000000  3.246873 -0.584746  2.691912  0.000007  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "18957  0.500000  3.380378  0.891985  2.384921 -0.510342  \n",
       "18958 -1.000000  5.153850 -0.563046  2.996383 -0.005741  \n",
       "18959  0.000000  3.600000  0.000000  3.117691  0.000000  \n",
       "18960  0.400000  3.324509 -1.130982  2.717591  1.195841  \n",
       "18961 -5.052521  3.480985 -0.678666  3.185616  0.030684  \n",
       "\n",
       "[18962 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[\"energy_per_atom\"] #select feature to predict\n",
    "toDrop=[\"material_id\", \"total_magnetization\", \"energy\", \"energy_per_atom\", \"band_gap\"] #drop the other predicted features, and id\n",
    "X=df.drop(columns=toDrop) #drop these unwanted features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For devices with no gpu, run this to hard code running on cpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf #reimport tesnorflow to make it work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18962.000000\n",
       "mean        -5.306329\n",
       "std          2.396340\n",
       "min        -13.701623\n",
       "25%         -7.084322\n",
       "50%         -5.076996\n",
       "75%         -3.473633\n",
       "max         -0.406819\n",
       "Name: energy_per_atom, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean=y.describe()[\"mean\"]\n",
    "y.describe() #print info about the data we want to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split input data into train and test datasets, using sklearn \n",
    "#test_size determines fraction for test set\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 42, test_size=0.20) \n",
    "train_X, val_X=train_X.to_numpy(), val_X.to_numpy()      #transfrom into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize input\n",
    "normalize=False                             #Normalization not done, experimentation showed it made network learning worse\n",
    "if normalize:                       \n",
    "    normaliser = preprocessing.Normalizer() #create a sklearn normlaizer\n",
    "\n",
    "    train_X=normaliser.fit_transform(train_X) #fit it and transform taining data\n",
    "    val_X=normaliser.transform(val_X) #use normalizer fitted to training data to normalize validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 7.00000000e+00  2.00000000e+00  1.00000000e+00 -0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  6.00000000e+00 -0.00000000e+00\n",
      "   8.00000000e+00 -0.00000000e+00  3.52921500e+00 -0.00000000e+00\n",
      "   3.05638985e+00 -0.00000000e+00]\n",
      " [ 1.25000000e+01  4.50000000e+00 -1.50000000e+00 -5.50000000e+00\n",
      "   1.90000000e+01  1.20000000e+01  5.91705069e+00 -3.68663594e-01\n",
      "   7.33179724e+00 -3.52534562e+00  4.21782865e+00 -1.21591730e+00\n",
      "   3.67584581e+00  9.47936229e-02]\n",
      " [ 2.00000000e+01  2.00000000e+00 -9.00000000e+00 -3.00000000e+00\n",
      "   1.20000000e+01  4.00000000e+00  8.00000000e+00  4.00000000e+00\n",
      "   3.00000000e+00 -1.00000000e+00  4.38002775e+00 -2.60846518e-08\n",
      "   2.68383659e+00  4.06497709e-08]\n",
      " [ 1.20000000e+01  2.00000000e+00 -2.00000000e+00 -2.00000000e+00\n",
      "   4.00000000e+00  2.00000000e+00  7.00000000e+00  1.00000000e+00\n",
      "   8.00000000e+00 -4.00000000e+00  3.17599390e+00 -5.61579160e-01\n",
      "   2.63869189e+00  3.64378230e-06]\n",
      " [ 1.05000000e+01  1.50000000e+00 -5.00000000e-01 -3.50000000e+00\n",
      "   1.45000000e+01  8.50000000e+00  6.00000000e+00  2.00000000e+00\n",
      "   7.69565217e+00 -4.30434783e+00  2.98738028e+00 -4.98326634e-01\n",
      "   2.96744532e+00  3.97806749e-02]], shape=(5, 14), dtype=float64)\n",
      "(128, 14)\n",
      "Data preprocessed\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "train_len=train_X.shape[0]\n",
    "val_len=val_X.shape[0]\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X, train_y))#make dataset from pandas dfs\n",
    "test_dataset=tf.data.Dataset.from_tensor_slices((val_X, val_y))\n",
    "                                  \n",
    "test_dataset = test_dataset.shuffle(val_len, seed=42).batch(batch_size) #shuffle datasets, batch them with batch_size\n",
    "train_dataset = train_dataset.shuffle(train_len, seed=42).batch(batch_size)\n",
    "\n",
    "features, labels=next(iter(train_dataset)) #just test and print some example feature matrices\n",
    "\n",
    "print(features[:5])\n",
    "print(features.shape) #shape of input tensor\n",
    "print(\"Data preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53, shape=(5,), dtype=float32, numpy=\n",
       "array([-4.9853425, -1.3426412, -1.4285034, -8.539671 , -7.731565 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5] #check that labels look good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build model. Start with simple 2 layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                750       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 6,501\n",
      "Trainable params: 6,201\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "\n",
    "    initial=tf.keras.initializers.he_normal(seed=42) #create initializer for \n",
    "\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(50, activation='relu', input_shape=[features.shape[1]], \n",
    "                    kernel_initializer=initial,\n",
    "                bias_initializer='zeros'), #first layer, takes input, 50 nodes\n",
    "        layers.BatchNormalization(), #batch normalization\n",
    "        layers.Dropout(0.5), #dropout\n",
    "        layers.Dense(50, activation='relu', kernel_initializer=initial, bias_initializer='zeros'), #second layer\n",
    "        layers.BatchNormalization(), #batch normalization\n",
    "        layers.Dropout(0.5), #dropout\n",
    "        layers.Dense(50, activation='relu', kernel_initializer=initial, bias_initializer='zeros'), #third layer\n",
    "        layers.BatchNormalization(), #batch normalization\n",
    "        layers.Dropout(0.5), #dropout\n",
    "        layers.Dense(1, kernel_initializer=\"zeros\", \n",
    "                     bias_initializer=keras.initializers.Constant(value=y_mean)) #output\n",
    "      ])  \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(model, x, y): #calculate loss during training\n",
    "    loss_Obj=tf.keras.losses.MeanSquaredError() #create a loss object to track losses\n",
    "    y_pred=model(x) #feed forward network\n",
    "    return loss_Obj(y_true=y, y_pred=y_pred) #calculate loss, return keras lossObj\n",
    "\n",
    "def grad(model, inputs, targets): #calculate gradients during backprop\n",
    "    with tf.GradientTape() as tape: #tensorflow gradienttape calculates gradients for all operations it is applied to\n",
    "        loss_value=mse(model, inputs, targets) #feed forward, calculate loss. tape is tracking thiS calculation!\n",
    "        return loss_value, tape.gradient(loss_value, model.trainable_variables) #return loss and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring time\n",
      "One epoch, time in minutes:\n",
      "0.07644506295522054\n"
     ]
    }
   ],
   "source": [
    "#This cell is only to test how long the training of network during one epoch takes\n",
    "import time\n",
    "optimizer = tf.keras.optimizers.Adam(5e-5) #use Adam optimizer\n",
    "print(\"Measuring time\")\n",
    "start_time=time.time() #start timer\n",
    "for x,y in train_dataset:    #iterate through all batches in dataset\n",
    "    loss_value, grads=grad(model, x, y) #calculate loss and gradients\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables)) #apply gradients to weights of model, using tf apply gradients function\n",
    "    #print(loss_value)\n",
    "print(\"One epoch, time in minutes:\")\n",
    "print((time.time()-start_time)/60)     #time in minutes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n",
      "Epoch000: Train loss 5.391, test loss 5.194.\n",
      "Epoch020: Train loss 1.710, test loss 1.664.\n",
      "Epoch040: Train loss 1.397, test loss 1.405.\n",
      "Epoch060: Train loss 1.264, test loss 1.274.\n",
      "Epoch080: Train loss 1.182, test loss 1.215.\n",
      "Epoch100: Train loss 1.128, test loss 1.195.\n",
      "Epoch120: Train loss 1.081, test loss 1.125.\n",
      "Epoch140: Train loss 1.046, test loss 1.117.\n",
      "Epoch160: Train loss 1.019, test loss 1.072.\n",
      "Epoch180: Train loss 0.999, test loss 1.049.\n",
      "Epoch200: Train loss 0.972, test loss 1.051.\n",
      "Epoch220: Train loss 0.956, test loss 1.014.\n",
      "Epoch240: Train loss 0.942, test loss 1.007.\n",
      "Epoch260: Train loss 0.919, test loss 0.977.\n",
      "Epoch280: Train loss 0.899, test loss 0.973.\n",
      "Epoch300: Train loss 0.896, test loss 0.987.\n",
      "Epoch320: Train loss 0.876, test loss 0.946.\n",
      "Epoch340: Train loss 0.872, test loss 0.939.\n",
      "Epoch360: Train loss 0.858, test loss 0.937.\n",
      "Epoch380: Train loss 0.845, test loss 0.921.\n",
      "Epoch400: Train loss 0.843, test loss 0.928.\n",
      "Epoch420: Train loss 0.830, test loss 0.901.\n",
      "Epoch440: Train loss 0.826, test loss 0.907.\n",
      "Epoch460: Train loss 0.822, test loss 0.908.\n",
      "Epoch480: Train loss 0.803, test loss 0.890.\n"
     ]
    }
   ],
   "source": [
    "#Main training loop\n",
    "EPOCHS = 500 #number of epochs\n",
    "optimizer = tf.keras.optimizers.Adam(1.5e-4)#use Adam optimizer\n",
    "train_losses=np.zeros(EPOCHS) #train losses to save\n",
    "val_losses=np.zeros(EPOCHS) #validation set losses to save\n",
    "print(\"Started training\")\n",
    "for i in range(EPOCHS):\n",
    "    epoch_loss_avg=tf.keras.metrics.Mean()      #keep track of mean training loss over the epoch\n",
    "    val_loss_avg=tf.keras.metrics.Mean()        #keep track of mean validation loss over the epoch\n",
    "    for x,y in train_dataset:                   #iterate through all batches in training dataset\n",
    "        loss_value, grads=grad(model, x, y)     #feedforward, then backprop to calculate loss and gradients\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables)) #apply gradients to weights of model, using tf apply gradients function\n",
    "        epoch_loss_avg(loss_value)              #add to mean loss tracker\n",
    "    train_losses[i]=epoch_loss_avg.result()     #save average train loss for epoch\n",
    "    for x,y in test_dataset:                    #iterate through all batches in validation dataset\n",
    "        loss_value, grads=grad(model, x, y)     #calculate loss, BUT DONT APPLY GRADIENTS\n",
    "        val_loss_avg(loss_value)                # add to mean val loss tracker\n",
    "    val_losses[i]=val_loss_avg.result()         #save average validation loss for epoch\n",
    "    if i%20==0:                                 #print info every 20th epoch\n",
    "        print(\"Epoch{:03d}: Train loss {:.3f}, test loss {:.3f}.\".format(i, epoch_loss_avg.result(), val_loss_avg.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.558197451756486, -5.23586401047443, -2.574705039915344, -3.669559620703625, -2.5327015127229533]\n",
      "[-8.132019465, -5.9827241275, -3.2247159266666667, -3.845365165, -2.9982032091666664]\n"
     ]
    }
   ],
   "source": [
    "preds=[]\n",
    "trues=[]\n",
    "for x,y in test_dataset:                    #iterate through all batches in validation dataset\n",
    "    pred=model(x)\n",
    "    pred=tf.reshape(pred, [-1])             #flatten output\n",
    "    true=tf.reshape(y, [-1])                #flatten true values\n",
    "    pred=list(pred.numpy())                 #turn tensor to numpy array\n",
    "    true=list(true.numpy())\n",
    "    preds=preds+pred                        #append to lists\n",
    "    trues=trues+true\n",
    "print(preds[0:5])\n",
    "print(trues[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.colors\n",
    "from matplotlib import cm\n",
    "\n",
    "colors=cm.get_cmap('Blues', 12)(np.linspace(0,1,16))\n",
    "colors[0]=np.array([1.,1.,1.,1.])\n",
    "\n",
    "newmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "plt.plot(np.arange(-14,0+1,1),np.arange(-14,0+1,1),'--',c='black')\n",
    "plt.hist2d(trues, preds,bins=[60,45],range=[[-14,0],[-14,0]],cmap=newmap) #plt.cm.Blues\n",
    "\n",
    "plt.margins(x=0)\n",
    "plt.xlabel('True energy (eV/atom)')\n",
    "plt.ylabel('Predicted energy (eV/atom)')\n",
    "\n",
    "plt.rc('xtick',labelsize=14)\n",
    "plt.rc('axes',labelsize=16)\n",
    "plt.rc('ytick',labelsize=14)\n",
    "plt.tick_params(direction='in')\n",
    "\n",
    "plt.gca().set_xlim([-10,0])\n",
    "plt.gca().set_ylim([-10,0])\n",
    "plt.xticks(np.arange(-10,0+2,2))\n",
    "plt.gca().set_aspect(0.75)\n",
    "        \n",
    "#plt.show()\n",
    "plt.savefig('Accuracy.pdf',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"4LayerNN.h5\") #save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on test set is: 0.8895925535400268\n"
     ]
    }
   ],
   "source": [
    "#Mean square error\n",
    "preds=np.array(preds)\n",
    "trues=np.array(trues)\n",
    "mse=np.mean(np.square(preds-trues))\n",
    "print(\"Mean squared error on test set is:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
