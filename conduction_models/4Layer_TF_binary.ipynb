{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from tensorflow_docs.plots import HistoryPlotter\n",
    "#from tensorflow_docs.modeling import EpochDots\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['material_id', 'energy', 'energy_per_atom', 'band_gap',\n",
       "       'total_magnetization', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       '10', '11', '12', '13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "path = \"../data/descriptor/DescriptorData.csv\"\n",
    "df=pd.read_csv(path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_id</th>\n",
       "      <th>energy</th>\n",
       "      <th>energy_per_atom</th>\n",
       "      <th>band_gap</th>\n",
       "      <th>total_magnetization</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16657</th>\n",
       "      <td>mp-19395</td>\n",
       "      <td>-85.492408</td>\n",
       "      <td>-7.124367</td>\n",
       "      <td>1.0729</td>\n",
       "      <td>1.500000e-07</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>2.688062</td>\n",
       "      <td>-0.187277</td>\n",
       "      <td>1.902257</td>\n",
       "      <td>0.004483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      material_id     energy  energy_per_atom  band_gap  total_magnetization  \\\n",
       "16657    mp-19395 -85.492408        -7.124367    1.0729         1.500000e-07   \n",
       "\n",
       "          0    1    2    3    4    5    6    7    8    9        10        11  \\\n",
       "16657  14.5  3.5 -8.5 -5.5  6.0  2.0  4.5  0.5  4.5 -1.5  2.688062 -0.187277   \n",
       "\n",
       "             12        13  \n",
       "16657  1.902257  0.004483  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect data\n",
    "df[df[\"material_id\"]==\"mp-19395\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.20000</td>\n",
       "      <td>-4.800000</td>\n",
       "      <td>4.413094</td>\n",
       "      <td>-1.060947</td>\n",
       "      <td>3.352150</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.805744</td>\n",
       "      <td>-4.097701</td>\n",
       "      <td>6.857758</td>\n",
       "      <td>4.503737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.188573</td>\n",
       "      <td>0.141018</td>\n",
       "      <td>2.782234</td>\n",
       "      <td>0.020056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.074499</td>\n",
       "      <td>0.527501</td>\n",
       "      <td>2.546999</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>3.246873</td>\n",
       "      <td>-0.584746</td>\n",
       "      <td>2.691912</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18957</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.380378</td>\n",
       "      <td>0.891985</td>\n",
       "      <td>2.384921</td>\n",
       "      <td>-0.510342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18958</th>\n",
       "      <td>14.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.153850</td>\n",
       "      <td>-0.563046</td>\n",
       "      <td>2.996383</td>\n",
       "      <td>-0.005741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18959</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.117691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18960</th>\n",
       "      <td>18.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>5.40000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.324509</td>\n",
       "      <td>-1.130982</td>\n",
       "      <td>2.717591</td>\n",
       "      <td>1.195841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18961</th>\n",
       "      <td>12.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>4.691877</td>\n",
       "      <td>2.406162</td>\n",
       "      <td>8.87605</td>\n",
       "      <td>-5.052521</td>\n",
       "      <td>3.480985</td>\n",
       "      <td>-0.678666</td>\n",
       "      <td>3.185616</td>\n",
       "      <td>0.030684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18962 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1     2    3     4     5         6         7        8  \\\n",
       "0       6.5  1.5   1.5  0.5   3.0   2.0  8.800000  0.800000  7.20000   \n",
       "1      17.5  3.5  -9.5 -3.5   1.5   0.5  3.500000 -2.500000  3.00000   \n",
       "2      15.5  5.5  -5.5 -5.5   5.0   1.0  4.333333  2.333333  5.00000   \n",
       "3      13.0  1.0  -5.0 -1.0   2.0  -1.0  7.000000 -1.000000  8.00000   \n",
       "4      12.0  3.0  -3.0 -2.0   4.0   2.0  7.000000  1.000000  8.00000   \n",
       "...     ...  ...   ...  ...   ...   ...       ...       ...      ...   \n",
       "18957  20.0  1.0 -13.0  2.0  10.0  -6.0  2.375000 -0.375000  2.50000   \n",
       "18958  14.5  5.5  -4.5 -7.5   9.0   3.0  4.000000 -0.000000  3.00000   \n",
       "18959  15.0  5.0  -4.0 -8.0   1.0   0.0  6.000000  0.000000  8.00000   \n",
       "18960  18.5  0.5 -13.5 -1.5   6.0   4.0  4.200000 -1.800000  5.40000   \n",
       "18961  12.5  3.5  -1.5 -4.5  32.5  18.5  4.691877  2.406162  8.87605   \n",
       "\n",
       "              9        10        11        12        13  \n",
       "0     -4.800000  4.413094 -1.060947  3.352150  0.000002  \n",
       "1      1.000000  8.805744 -4.097701  6.857758  4.503737  \n",
       "2     -1.000000  3.188573  0.141018  2.782234  0.020056  \n",
       "3      4.000000  3.074499  0.527501  2.546999 -0.000000  \n",
       "4     -4.000000  3.246873 -0.584746  2.691912  0.000007  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "18957  0.500000  3.380378  0.891985  2.384921 -0.510342  \n",
       "18958 -1.000000  5.153850 -0.563046  2.996383 -0.005741  \n",
       "18959  0.000000  3.600000  0.000000  3.117691  0.000000  \n",
       "18960  0.400000  3.324509 -1.130982  2.717591  1.195841  \n",
       "18961 -5.052521  3.480985 -0.678666  3.185616  0.030684  \n",
       "\n",
       "[18962 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[\"band_gap\"] #select feature to predict\n",
    "toDrop=[\"material_id\", \"total_magnetization\", \"energy\", \"energy_per_atom\", \"band_gap\"] #drop the other predicted features, and id\n",
    "X=df.drop(columns=toDrop) #drop these unwanted features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For devices with no gpu, run this to hard code running on cpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf #reimport tesnorflow to make it work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "18957     True\n",
       "18958     True\n",
       "18959    False\n",
       "18960     True\n",
       "18961    False\n",
       "Name: band_gap, Length: 18962, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y>0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split input data into train and test datasets, using sklearn \n",
    "#test_size determines fraction for test set\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 42, test_size=0.20, stratify=y) \n",
    "train_X, val_X=train_X.to_numpy(), val_X.to_numpy()      #transfrom into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize input\n",
    "normalize=False                             #Normalization not done, experimentation showed it made network learning worse\n",
    "if normalize:                       \n",
    "    normaliser = preprocessing.Normalizer() #create a sklearn normlaizer\n",
    "\n",
    "    train_X=normaliser.fit_transform(train_X) #fit it and transform taining data\n",
    "    val_X=normaliser.transform(val_X) #use normalizer fitted to training data to normalize validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.05000000e+01  7.50000000e+00 -2.50000000e+00 -3.50000000e+00\n",
      "   4.00000000e+00 -2.00000000e+00  7.00000000e+00 -1.00000000e+00\n",
      "   8.00000000e+00  4.00000000e+00  3.34401976e+00  6.01852895e-01\n",
      "   2.77650011e+00 -2.31335672e-06]\n",
      " [ 1.10000000e+01  6.00000000e+00 -5.00000000e+00 -6.00000000e+00\n",
      "   1.10000000e+01 -1.00000000e+00  2.65000000e+00 -8.50000000e-01\n",
      "   4.45000000e+00  4.50000000e-01  2.86607418e+00 -2.24909357e-01\n",
      "   2.88687820e+00 -2.99392834e-03]\n",
      " [ 9.00000000e+00  1.00000000e+00  4.00000000e+00 -0.00000000e+00\n",
      "   2.00000000e+00 -1.00000000e+00  6.00000000e+00 -2.00000000e+00\n",
      "   8.00000000e+00  4.00000000e+00  4.81345857e+00  8.21503427e-01\n",
      "   3.99195515e+00 -7.43530353e-03]\n",
      " [ 1.05000000e+01  1.50000000e+00 -1.50000000e+00 -2.50000000e+00\n",
      "   1.20000000e+01 -4.00000000e+00  4.50000000e+00 -1.50000000e+00\n",
      "   3.75000000e+00 -7.50000000e-01  2.79753488e+00 -2.22251987e-01\n",
      "   2.74197189e+00 -1.66688990e-01]\n",
      " [ 1.25000000e+01  6.50000000e+00 -5.50000000e+00 -9.50000000e+00\n",
      "   2.00000000e+00  1.00000000e+00  7.00000000e+00  1.00000000e+00\n",
      "   8.00000000e+00 -4.00000000e+00  3.37267089e+00 -5.78662115e-01\n",
      "   2.79401157e+00  2.79401715e-06]], shape=(5, 14), dtype=float64)\n",
      "(128, 14)\n",
      "Data preprocessed\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "train_len=train_X.shape[0]\n",
    "val_len=val_X.shape[0]\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_X, train_y))#make dataset from pandas dfs\n",
    "test_dataset=tf.data.Dataset.from_tensor_slices((val_X, val_y))\n",
    "                                  \n",
    "test_dataset = test_dataset.shuffle(val_len, seed=42).batch(batch_size) #shuffle datasets, batch them with batch_size\n",
    "train_dataset = train_dataset.shuffle(train_len, seed=42).batch(batch_size)\n",
    "\n",
    "features, labels=next(iter(train_dataset)) #just test and print some example feature matrices\n",
    "\n",
    "print(features[:5])\n",
    "print(features.shape) #shape of input tensor\n",
    "print(\"Data preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=53, shape=(5,), dtype=bool, numpy=array([False, False, False, False, False])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5] #check that labels look good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build model. Start with simple 2 layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                750       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 6,501\n",
      "Trainable params: 6,201\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "\n",
    "    initial=tf.keras.initializers.he_normal(seed=42) #create initializer for \n",
    "\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(50, activation='relu', input_shape=[features.shape[1]], \n",
    "                    kernel_initializer=initial,\n",
    "                bias_initializer='zeros'), #first layer, takes input, 50 nodes\n",
    "        layers.BatchNormalization(), #batch normalization\n",
    "        layers.Dropout(0.5), #dropout\n",
    "        layers.Dense(50, activation='relu', kernel_initializer=initial, bias_initializer='zeros'), #second layer\n",
    "        layers.BatchNormalization(), #batch normalization\n",
    "        layers.Dropout(0.5), #dropout\n",
    "        layers.Dense(50, activation='relu', kernel_initializer=initial, bias_initializer='zeros'), #third layer\n",
    "        layers.BatchNormalization(), #batch normalization\n",
    "        layers.Dropout(0.5), #dropout\n",
    "        layers.Dense(1, activation='sigmoid', kernel_initializer=initial, \n",
    "                     bias_initializer='zeros') #output\n",
    "      ])  \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(model, x, y): #calculate loss during training\n",
    "    loss_Obj=tf.keras.losses.BinaryCrossentropy() #create a loss object to track losses. Binary cross entropy for bianry classification.\n",
    "    y_pred=model(x) #feed forward network\n",
    "    return loss_Obj(y_true=y, y_pred=y_pred) #calculate loss, return keras lossObj\n",
    "\n",
    "def grad(model, inputs, targets): #calculate gradients during backprop\n",
    "    with tf.GradientTape() as tape: #tensorflow gradienttape calculates gradients for all operations it is applied to\n",
    "        loss_value=mse(model, inputs, targets) #feed forward, calculate loss. tape is tracking thiS calculation!\n",
    "        return loss_value, tape.gradient(loss_value, model.trainable_variables) #return loss and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring time\n",
      "One epoch, time in minutes:\n",
      "0.07294364770253499\n"
     ]
    }
   ],
   "source": [
    "#This cell is only to test how long the training of network during one epoch takes\n",
    "import time\n",
    "optimizer = tf.keras.optimizers.Adam(5e-5) #use Adam optimizer\n",
    "print(\"Measuring time\")\n",
    "start_time=time.time() #start timer\n",
    "for x,y in train_dataset:    #iterate through all batches in dataset\n",
    "    loss_value, grads=grad(model, x, y) #calculate loss and gradients\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables)) #apply gradients to weights of model, using tf apply gradients function\n",
    "    #print(loss_value)\n",
    "print(\"One epoch, time in minutes:\")\n",
    "print((time.time()-start_time)/60)     #time in minutes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n",
      "Epoch000: Train loss 0.589, test loss 0.455.\n",
      "Epoch020: Train loss 0.295, test loss 0.308.\n",
      "Epoch040: Train loss 0.276, test loss 0.298.\n",
      "Epoch060: Train loss 0.263, test loss 0.286.\n",
      "Epoch080: Train loss 0.256, test loss 0.284.\n",
      "Epoch100: Train loss 0.251, test loss 0.276.\n",
      "Epoch120: Train loss 0.244, test loss 0.276.\n",
      "Epoch140: Train loss 0.240, test loss 0.277.\n",
      "Epoch160: Train loss 0.235, test loss 0.272.\n",
      "Epoch180: Train loss 0.230, test loss 0.275.\n"
     ]
    }
   ],
   "source": [
    "#Main training loop\n",
    "EPOCHS = 200 #number of epochs\n",
    "optimizer = tf.keras.optimizers.Adam(1.5e-4)#use Adam optimizer\n",
    "train_losses=np.zeros(EPOCHS) #train losses to save\n",
    "val_losses=np.zeros(EPOCHS) #validation set losses to save\n",
    "print(\"Started training\")\n",
    "for i in range(EPOCHS):\n",
    "    epoch_loss_avg=tf.keras.metrics.Mean()      #keep track of mean training loss over the epoch\n",
    "    val_loss_avg=tf.keras.metrics.Mean()        #keep track of mean validation loss over the epoch\n",
    "    for x,y in train_dataset:                   #iterate through all batches in training dataset\n",
    "        loss_value, grads=grad(model, x, y)     #feedforward, then backprop to calculate loss and gradients\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables)) #apply gradients to weights of model, using tf apply gradients function\n",
    "        epoch_loss_avg(loss_value)              #add to mean loss tracker\n",
    "    train_losses[i]=epoch_loss_avg.result()     #save average train loss for epoch\n",
    "    for x,y in test_dataset:                    #iterate through all batches in validation dataset\n",
    "        loss_value, grads=grad(model, x, y)     #calculate loss, BUT DONT APPLY GRADIENTS\n",
    "        val_loss_avg(loss_value)                # add to mean val loss tracker\n",
    "    val_losses[i]=val_loss_avg.result()         #save average validation loss for epoch\n",
    "    if i%20==0:                                 #print info every 20th epoch\n",
    "        print(\"Epoch{:03d}: Train loss {:.3f}, test loss {:.3f}.\".format(i, epoch_loss_avg.result(), val_loss_avg.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0521859033551634, 0.9370093313757315, 0.08812471980817048, 0.02986234952817938, 0.008069628730145353]\n",
      "[False, True, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "preds=[]\n",
    "trues=[]\n",
    "for x,y in test_dataset:                    #iterate through all batches in validation dataset\n",
    "    pred=model(x)\n",
    "    pred=tf.reshape(pred, [-1])             #flatten output\n",
    "    true=tf.reshape(y, [-1])                #flatten true values\n",
    "    pred=list(pred.numpy())                 #turn tensor to numpy array\n",
    "    true=list(true.numpy())\n",
    "    preds=preds+pred                        #append to lists\n",
    "    trues=trues+true\n",
    "print(preds[0:5])   #return lists of predicted propabilities and \n",
    "print(trues[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(trues, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.8879514895860796\n"
     ]
    }
   ],
   "source": [
    "y_pred=np.array(preds)>0.5\n",
    "accuracy=np.mean(y_pred==np.array(trues))\n",
    "print(\"Accuracy is:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'Pred_4NN': preds, 'Real_4NN': trues}  \n",
    "df=pd.DataFrame(dict1)\n",
    "df.to_csv(\"4LayerNNData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"4LayerNN.h5\") #save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
